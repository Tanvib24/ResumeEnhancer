{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b9382a-00d4-4252-945b-1fc648b3d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "\n",
    "# Function to clean resume text\n",
    "def clean_resume(text):\n",
    "    text = re.sub('http\\S+\\s*', ' ', text)  # Remove URLs\n",
    "    text = re.sub('RT|cc', ' ', text)  # Remove RT and cc\n",
    "    text = re.sub('#\\S+', '', text)  # Remove hashtags\n",
    "    text = re.sub('@\\S+', '  ', text)  # Remove mentions\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)  # Remove punctuations\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ', text)  # Remove non-ASCII characters\n",
    "    text = re.sub('\\s+', ' ', text)  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function\n",
    "df['cleaned_resume'] = df['Resume'].apply(lambda x: clean_resume(x))\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "df['Category_encoded'] = le.fit_transform(df['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1164d3-ab72-4636-b275-916f758c0a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         3\n",
      "                     Arts       1.00      1.00      1.00         6\n",
      "       Automation Testing       1.00      1.00      1.00         5\n",
      "               Blockchain       1.00      1.00      1.00         7\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         9\n",
      "             Data Science       1.00      1.00      1.00         5\n",
      "                 Database       1.00      1.00      1.00         8\n",
      "          DevOps Engineer       1.00      0.93      0.96        14\n",
      "         DotNet Developer       1.00      1.00      1.00         5\n",
      "            ETL Developer       1.00      1.00      1.00         7\n",
      "   Electrical Engineering       1.00      1.00      1.00         6\n",
      "                       HR       1.00      1.00      1.00        12\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         7\n",
      "           Java Developer       1.00      1.00      1.00        15\n",
      "      Mechanical Engineer       1.00      1.00      1.00         8\n",
      "Network Security Engineer       1.00      1.00      1.00         3\n",
      "       Operations Manager       1.00      1.00      1.00        12\n",
      "                      PMO       0.88      1.00      0.93         7\n",
      "         Python Developer       1.00      1.00      1.00        10\n",
      "            SAP Developer       1.00      1.00      1.00         7\n",
      "                    Sales       1.00      1.00      1.00         8\n",
      "                  Testing       1.00      1.00      1.00        16\n",
      "            Web Designing       1.00      1.00      1.00         5\n",
      "\n",
      "                 accuracy                           0.99       193\n",
      "                macro avg       0.99      1.00      1.00       193\n",
      "             weighted avg       1.00      0.99      0.99       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1500)\n",
    "X = tfidf.fit_transform(df['cleaned_resume'])\n",
    "y = df['Category_encoded']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a45d19-6d76-4e26-ba62-e9dcc6e3bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Java Developer\n",
      "Suggested Keywords to Include:\n",
      "['java', 'developer', 'exprience', 'months', 'jsp', 'ajax', 'spring', 'j2ee', 'hibernate', 'servlet']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to get top keywords for each category\n",
    "def get_top_keywords(category, n=10):\n",
    "    category_indices = df[df['Category'] == category].index\n",
    "    category_tfidf = X[category_indices]\n",
    "    mean_tfidf = np.mean(category_tfidf.toarray(), axis=0)\n",
    "    top_n_indices = mean_tfidf.argsort()[::-1][:n]\n",
    "    top_keywords = [tfidf.get_feature_names_out()[i] for i in top_n_indices]\n",
    "    return top_keywords\n",
    "\n",
    "# Example usage\n",
    "predicted_category = le.inverse_transform([y_pred[0]])[0]\n",
    "print(f\"Predicted Category: {predicted_category}\")\n",
    "print(\"Suggested Keywords to Include:\")\n",
    "print(get_top_keywords(predicted_category))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ceeda7f-efe6-45e7-af31-07be16d383c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.2893987855122808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(resume_text, job_description):\n",
    "    resume_vec = tfidf.transform([resume_text])\n",
    "    job_desc_vec = tfidf.transform([job_description])\n",
    "    similarity = cosine_similarity(resume_vec, job_desc_vec)\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Example usage\n",
    "resume_text = df['cleaned_resume'].iloc[0]\n",
    "job_description = \"Looking for a Data Scientist with experience in Python, Machine Learning, and Data Analysis.\"\n",
    "similarity_score = compute_similarity(resume_text, job_description)\n",
    "print(f\"Similarity Score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ee1df2-7b2c-4602-9c1b-f86c53debc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Original Resume:\n",
      " SOFTWARE SKILLS: √¢¬Ä¬¢ General Computer Proficiency √¢¬Ä¬¢ Program Langages known C, C+, Java, Web Programming √¢¬Ä¬¢ Tools & Software know MATLAB. DBMS KEY STRENGTHS: √¢¬Ä¬¢ Posse's Good communication and analytic skills. √¢¬Ä¬¢ Positive thinking. Sincere, Hard work, Honesty, Responsibility. √¢¬Ä¬¢ Enthusiastic to learn new skills & take up new tasks. √¢¬Ä¬¢ Self - motivated. √¢¬Ä¬¢ Ready to accept challenges Education Details \r\n",
      "January 2014 to January 2017 BE in computer science and engineering computer science engi ...\n",
      "\n",
      "üîç Predicted Category: HR\n",
      "\n",
      "‚ú® Suggested Keywords to Add:\n",
      "['mba', 'chennai', 'june', 'finance', '2012', 'college', 'university']\n",
      "\n",
      "üìà Resume-Job Description Similarity Score: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Example: Choose a specific resume (say, index 10)\n",
    "index = 50\n",
    "sample_resume_raw = df['Resume'].iloc[index]\n",
    "sample_resume_cleaned = df['cleaned_resume'].iloc[index]\n",
    "\n",
    "# Transform using the same TF-IDF vectorizer\n",
    "sample_vector = tfidf.transform([sample_resume_cleaned])\n",
    "\n",
    "# Predict category\n",
    "predicted_label = model.predict(sample_vector)[0]\n",
    "predicted_category = le.inverse_transform([predicted_label])[0]\n",
    "print(\"üìù Original Resume:\\n\", sample_resume_raw[:500], \"...\")  # Print a portion of the resume\n",
    "print(\"\\nüîç Predicted Category:\", predicted_category)\n",
    "\n",
    "# Enhancement Suggestions\n",
    "def suggest_missing_keywords(cleaned_resume, predicted_category):\n",
    "    resume_words = set(cleaned_resume.lower().split())\n",
    "    top_keywords = get_top_keywords(predicted_category, n=15)\n",
    "    missing_keywords = [kw for kw in top_keywords if kw not in resume_words]\n",
    "    return missing_keywords\n",
    "\n",
    "print(\"\\n‚ú® Suggested Keywords to Add:\")\n",
    "print(suggest_missing_keywords(sample_resume_cleaned, predicted_category))\n",
    "\n",
    "# Optional: Compare against a sample job description\n",
    "sample_job_desc = \"\"\"We are looking for a skilled Machine Learning Engineer to help us build and optimize data-driven solutions. \n",
    "The candidate should have strong experience with Python, machine learning libraries (Scikit-learn, TensorFlow, PyTorch), \n",
    "and working with large datasets. Familiarity with model deployment, data preprocessing, and cloud platforms (AWS, GCP) is a plus.\"\"\"\n",
    "\n",
    "similarity_score = compute_similarity(sample_resume_cleaned, sample_job_desc)\n",
    "print(\"\\nüìà Resume-Job Description Similarity Score:\", round(similarity_score, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e03fa3-8f3c-434e-9bee-45aafb62b439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
